{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_clustering1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNR/NWd/y4kPHOKtXpvmfX8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/u-keigo/RRIproject1/blob/main/LSTM_clustering1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eZxNXc0qlET"
      },
      "source": [
        "# LSTMによる文章分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcF3M_rBq0G3"
      },
      "source": [
        "参考：https://qiita.com/m__k/items/841950a57a0d7ff05506"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XVu1lCdLFeP",
        "outputId": "d3515984-f20c-4804-ea60-35954a532941"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "T5Q3iGcfq55j",
        "outputId": "d1ae5e61-3c7e-4356-97c3-9bb76fe37269"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import linecache\n",
        "\n",
        "# カテゴリを配列で取得\n",
        "drive_dir = \"/content/drive/My Drive/python/\"\n",
        "\n",
        "categories = [name for name in os.listdir(drive_dir + 'text') if os.path.isdir(drive_dir + \"text/\" +name)]\n",
        "print(categories)\n",
        "\n",
        "datasets = pd.DataFrame(columns=[\"title\", \"category\"])\n",
        "for cat in categories:\n",
        "    path = drive_dir + \"text/\" + cat + \"/*.txt\"\n",
        "    files = glob(path)\n",
        "    for text_name in files:\n",
        "        title = linecache.getline(text_name, 3)\n",
        "        s = pd.Series([title, cat], index=datasets.columns)\n",
        "        datasets = datasets.append(s, ignore_index=True)\n",
        "\n",
        "# データフレームシャッフル\n",
        "datasets = datasets.sample(frac=1).reset_index(drop=True)\n",
        "datasets.head()\n",
        "#title  category\n",
        "#0  兼用アンテナ搭載の「Viewer Dock」が同梱！シャープのドコモ向けハイエンドエンタメ系... smax\n",
        "#1  女は“愛嬌”、男も“愛嬌”-人事担当者がこっそり教える採用ウラ話 vol.6\\n  livedoor-homme\n",
        "#2  社会貢献×ファッションがカッコイイ、今年の春旋風を巻き起こしたMODE for Charit...  peachy\n",
        "#3  今でも、後でも読めるニュースがここにある！スマホでもタブレットでも読みやすいITニュース活用...   it-life-hack\n",
        "#4  被災地の缶詰を途上国に…「正気じゃない。人殺しだ!!」\\n topic-news"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['peachy', 'livedoor-homme', 'it-life-hack', 'movie-enter', 'sports-watch', 'smax', 'kaden-channel', 'dokujo-tsushin', 'topic-news']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>【Sports Watch】應武監督、斎藤らに最後の教え。“プロはとんでもない世界”\\n</td>\n",
              "      <td>sports-watch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>グローバルで差をつけろ！HYBRID W-ZERO3【新生活特集】\\n</td>\n",
              "      <td>livedoor-homme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>タブの多段表示やウィンドウのシングル表示　Firefoxを強化しよう【知っ得！虎の巻】\\n</td>\n",
              "      <td>it-life-hack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>【独女的コミックレビュー】vol.6 『姉の結婚』に見る“枯れ気味女”の憂鬱\\n</td>\n",
              "      <td>dokujo-tsushin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ミス・ユニバース・ジャパンも習った「柔術」で、護身術をお試し！\\n</td>\n",
              "      <td>peachy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           title        category\n",
              "0   【Sports Watch】應武監督、斎藤らに最後の教え。“プロはとんでもない世界”\\n    sports-watch\n",
              "1            グローバルで差をつけろ！HYBRID W-ZERO3【新生活特集】\\n  livedoor-homme\n",
              "2  タブの多段表示やウィンドウのシングル表示　Firefoxを強化しよう【知っ得！虎の巻】\\n    it-life-hack\n",
              "3       【独女的コミックレビュー】vol.6 『姉の結婚』に見る“枯れ気味女”の憂鬱\\n  dokujo-tsushin\n",
              "4              ミス・ユニバース・ジャパンも習った「柔術」で、護身術をお試し！\\n          peachy"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9suvNmptzg9",
        "outputId": "500799ea-283d-413e-9b34-7bf304b805b3"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 以下の宣言で行が単語ベクトル、列が単語のインデックスのマトリクスを生成してる感じ\n",
        "embeds = nn.Embedding(10, 6) # (Embedding(単語の合計数, ベクトル次元数))\n",
        "\n",
        "# ３行目の要素を取り出したいならば\n",
        "w1 = torch.tensor([2])\n",
        "print(embeds(w1))\n",
        "# tensor([[-1.5947, -0.8387,  0.7669, -0.9644, -0.7902,  2.7167]],\n",
        "#        grad_fn=<EmbeddingBackward>)\n",
        "\n",
        "# 3行目、5行目、１０行目の要素を取り出したいならば、\n",
        "w2 = torch.tensor([2,4,9])\n",
        "print(embeds(w2))\n",
        "# tensor([[-1.5947, -0.8387,  0.7669, -0.9644, -0.7902,  2.7167],\n",
        "#        [ 0.0405,  1.4236,  0.1947,  0.2609,  0.2047, -1.4964],\n",
        "#        [ 1.7325, -0.2543, -0.5139, -0.9527, -0.1344,  0.0984]],\n",
        "#       grad_fn=<EmbeddingBackward>)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5400,  0.9701,  1.7957,  0.3261,  1.2800, -0.1958]],\n",
            "       grad_fn=<EmbeddingBackward>)\n",
            "tensor([[-0.5400,  0.9701,  1.7957,  0.3261,  1.2800, -0.1958],\n",
            "        [ 0.4320,  0.6343, -1.6826,  1.1063, -0.2363,  1.2425],\n",
            "        [-0.8309, -0.0217, -1.7661, -0.8426,  0.3200, -0.1763]],\n",
            "       grad_fn=<EmbeddingBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srG9w1s7WNiQ",
        "outputId": "4cc5d27e-b376-4bab-a92b-e9dd321a66e5"
      },
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aptitude is already the newest version (0.8.10-6ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.9)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.16)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.9)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.16)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "No packages will be installed, upgraded, or removed.\n",
            "0 packages upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 0 B of archives. After unpacking 0 B will be used.\n",
            "                            \n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.7/dist-packages (0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X1e8JeQuCJM",
        "outputId": "5ca9d442-f6ae-4449-88ea-5affe93a5a9d"
      },
      "source": [
        "import MeCab\n",
        "import re\n",
        "import torch\n",
        "\n",
        "tagger = MeCab.Tagger(\"-Owakati\")\n",
        "\n",
        "def make_wakati(sentence):\n",
        "    # MeCabで分かち書き\n",
        "    sentence = tagger.parse(sentence)\n",
        "    # 半角全角英数字除去\n",
        "    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n",
        "    # 記号もろもろ除去\n",
        "    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n",
        "    # スペースで区切って形態素の配列へ\n",
        "    wakati = sentence.split(\" \")\n",
        "    # 空の要素は削除\n",
        "    wakati = list(filter((\"\").__ne__, wakati))\n",
        "    return wakati\n",
        "\n",
        "# テスト\n",
        "test = \"【人工知能】は「人間」の仕事を奪った\"\n",
        "print(make_wakati(test))\n",
        "# ['人工', '知能', 'は', '人間', 'の', '仕事', 'を', '奪っ', 'た']\n",
        "\n",
        "# 単語ID辞書を作成する\n",
        "word2index = {}\n",
        "for title in datasets[\"title\"]:\n",
        "    wakati = make_wakati(title)\n",
        "    for word in wakati:\n",
        "        if word in word2index: continue\n",
        "        word2index[word] = len(word2index)\n",
        "print(\"vocab size : \", len(word2index))\n",
        "# vocab size :  13229\n",
        "\n",
        "# 文章を単語IDの系列データに変換\n",
        "# PyTorchのLSTMのインプットになるデータなので、もちろんtensor型で\n",
        "def sentence2index(sentence):\n",
        "    wakati = make_wakati(sentence)\n",
        "    return torch.tensor([word2index[w] for w in wakati], dtype=torch.long)\n",
        "\n",
        "# テスト\n",
        "test = \"例のあのメニューも！ニコニコ超会議のフードコートメニュー14種類紹介（前半）\"\n",
        "print(sentence2index(test))\n",
        "# tensor([11320,     3,   449,  5483,    26,  3096,  1493,  1368,     3, 11371, 7835,   174,  8280])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['人工', '知能', 'は', '人間', 'の', '仕事', 'を', '奪っ', 'た']\n",
            "vocab size :  13229\n",
            "tensor([ 7013,     6,  5155,   880,    46,  2541,  1681,   501,     6, 12574,\n",
            "         8974,  1023,  6487])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a93pLUI1uDrt",
        "outputId": "dfbaacfc-512f-4f11-fed7-e10eaff0b2c9"
      },
      "source": [
        "# 全単語数を取得\n",
        "VOCAB_SIZE = len(word2index)\n",
        "# 単語のベクトル数\n",
        "EMBEDDING_DIM = 10\n",
        "test = \"ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」\"\n",
        "# 単語IDの系列データに変換\n",
        "inputs = sentence2index(test)\n",
        "# 各単語のベクトルをまとめて取得\n",
        "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
        "sentence_matrix = embeds(inputs)\n",
        "print(sentence_matrix.size())\n",
        "print(sentence_matrix)\n",
        "#torch.Size([13, 10])\n",
        "#tensor([[ 0.5991,  0.2086,  1.6805, -0.2688, -0.5661,  1.0238, -0.8815,  2.0745, 0.8218, -1.0922],\n",
        "#        [-0.7200,  1.3530, -1.7728, -0.3340, -0.2927, -0.2114,  0.1669,  1.4174, 1.0367, -0.1559],\n",
        "#        [ 2.0492, -0.0129, -0.1688, -0.4127, -1.8662,  0.6761,  0.0921,  0.3018, 0.0510, -0.9186],\n",
        "#        [-0.0932, -0.4891,  0.5047, -0.2488, -2.6789,  0.3175,  0.4011,  0.9005, 0.8657, -0.7729],\n",
        "#        [ 0.6532,  0.8718, -0.6497,  0.5400, -0.1419,  0.8451, -0.5677,  0.1743, -0.0216,  0.8146],\n",
        "#        [-1.2233, -0.9399,  0.2994,  0.9843,  0.6436, -0.1621,  0.6975, -0.4586, 0.9937, -0.4859],\n",
        "#        [ 1.1178, -1.2890,  0.6551, -0.3249, -0.1036, -0.4176, -1.6938, -0.6290, -2.7653, -0.1765],\n",
        "#        [ 0.5090,  1.4671, -0.8971,  1.3293, -0.5948, -1.7585,  0.0609,  0.1469, -0.9665, -0.4266],\n",
        "#        [-0.7200,  1.3530, -1.7728, -0.3340, -0.2927, -0.2114,  0.1669,  1.4174, 1.0367, -0.1559],\n",
        "#        [ 0.6907,  1.8703,  0.1093, -0.2989, -0.7074, -0.1824, -1.1053,  0.6469, -1.0702,  2.3492],\n",
        "#        [ 1.1241, -0.8715,  0.4012, -0.5327, -0.1104,  1.7967, -0.9907,  1.4248, -1.7789,  1.6670],\n",
        "#        [ 0.2470,  1.8372,  0.9765,  0.5153,  0.0936,  0.2957, -1.7517, -0.0556, -2.0370, -0.7433],\n",
        "#        [-0.3896,  1.6902, -2.0145, -0.0156,  0.4149,  0.7111,  1.3389, -0.1780, -1.5560, -1.0672]], \n",
        "#        grad_fn=<EmbeddingBackward>)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([13, 10])\n",
            "tensor([[-1.5200, -0.4930, -0.2387, -0.2176,  1.4628,  0.0153,  1.7628,  0.9878,\n",
            "         -1.7934, -3.2405],\n",
            "        [ 0.1714, -0.0461,  0.1016,  0.4132,  0.3403,  0.0597,  1.0682, -0.0515,\n",
            "         -0.1603,  0.1370],\n",
            "        [ 0.0352,  1.3858,  0.3910,  0.1796,  0.0926, -0.8761,  0.3441, -1.4594,\n",
            "         -0.5751, -0.2654],\n",
            "        [-0.0450,  1.9036,  0.2475,  0.8978,  1.8762, -0.9210, -0.7353, -0.5800,\n",
            "          1.5283,  0.1431],\n",
            "        [-2.0430,  0.0901,  1.0027, -1.1278, -0.2474,  1.4183,  0.4669, -1.8924,\n",
            "         -2.5465,  0.4438],\n",
            "        [ 2.0239, -0.1796,  0.5589,  0.0915, -0.4644, -0.7950, -1.6049, -0.0568,\n",
            "          0.7983, -0.7200],\n",
            "        [ 0.5676,  1.3695,  0.6456, -0.3103,  0.4275, -0.3117,  1.0550, -1.7020,\n",
            "          0.8385, -0.6031],\n",
            "        [ 0.3800, -0.4874, -1.7723,  0.1058,  1.8267, -0.9844,  0.4826,  0.0286,\n",
            "          0.8099, -0.4022],\n",
            "        [ 0.1714, -0.0461,  0.1016,  0.4132,  0.3403,  0.0597,  1.0682, -0.0515,\n",
            "         -0.1603,  0.1370],\n",
            "        [-0.1713, -1.4980, -0.3287, -1.4766,  0.4513, -1.0270,  1.8908,  0.3776,\n",
            "          0.3218,  1.0754],\n",
            "        [ 1.0994,  1.3868,  1.8464,  0.0285, -0.0892,  0.4051, -1.6367,  0.7627,\n",
            "          0.4689, -0.0649],\n",
            "        [-0.3157, -1.0426, -2.8804,  0.3392, -1.4617,  0.5212,  0.0283, -0.5200,\n",
            "         -0.2740, -2.0654],\n",
            "        [ 0.1579, -1.2777,  0.5293, -0.2444,  1.3476,  2.2844, -0.3663, -0.6523,\n",
            "         -0.2224, -0.4351]], grad_fn=<EmbeddingBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcIrWrSduHeH",
        "outputId": "9bd4fc5f-8852-4320-8101-a31d643b72b5"
      },
      "source": [
        "sentence_matrix.view(len(sentence_matrix), 1, -1).size()\n",
        "# torch.Size([13, 1, 10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHABDZ35uLbg",
        "outputId": "ddaf1fe5-d97e-444e-de8a-0734b6c8dd58"
      },
      "source": [
        "VOCAB_SIZE = len(word2index)\n",
        "EMBEDDING_DIM = 10\n",
        "HIDDEN_DIM = 128\n",
        "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
        "lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM)\n",
        "s1 = \"震災をうけて感じた、大切だと思ったこと\"\n",
        "print(make_wakati(s1))\n",
        "#['震災', 'を', 'うけ', 'て', '感じ', 'た', '大切', 'だ', 'と', '思っ', 'た', 'こと']\n",
        "\n",
        "inputs1 = sentence2index(s1)\n",
        "emb1 = embeds(inputs1)\n",
        "lstm_inputs1 = emb1.view(len(inputs1), 1, -1)\n",
        "out1, out2 = lstm(lstm_inputs1)\n",
        "print(out1)\n",
        "print(out2)\n",
        "# out1\n",
        "#tensor([[[-0.0146, -0.0069,  0.0323,  ..., -0.0091, -0.0313,  0.0114]],\n",
        "#        [[-0.0321, -0.0447,  0.0491,  ...,  0.0175, -0.0253,  0.0031]],\n",
        "#        [[-0.0091, -0.0532,  0.0144,  ..., -0.0411, -0.0329, -0.0310]],\n",
        "#        ...,\n",
        "#        [[-0.0061,  0.0423,  0.0123,  ..., -0.0647, -0.0303, -0.0459]],\n",
        "#        [[-0.0410,  0.0180,  0.0554,  ..., -0.0595, -0.0158, -0.0479]],\n",
        "#        [[ 0.0323, -0.0564, -0.0181,  ...,  0.0236, -0.0057,  0.0101]]],\n",
        "#       grad_fn=<StackBackward>)\n",
        "# out2\n",
        "#(tensor([[[ 0.0323, -0.0564, -0.0181,  0.0247, -0.0147,  0.0248,  0.0125,\n",
        "#          (長いので省略)\n",
        "#          -0.0057,  0.0101]]], grad_fn=<StackBackward>), \n",
        "#          tensor([[[ 0.0711, -0.1137, -0.0448,  0.0477, -0.0253,  0.0564,  0.0251,\n",
        "#          -0.1323,  0.1250,  0.0682,  0.0218, -0.0083, -0.0245,  0.0315,\n",
        "#          (長いので省略)\n",
        "#          -0.0124,  0.0266]]], grad_fn=<StackBackward>))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['震災', 'を', 'うけ', 'て', '感じ', 'た', '大切', 'だ', 'と', '思っ', 'た', 'こと']\n",
            "tensor([[[-4.3445e-02, -2.8424e-02,  1.6503e-02,  ...,  7.7154e-02,\n",
            "           3.5013e-02, -3.6983e-03]],\n",
            "\n",
            "        [[-3.5100e-02, -1.0500e-01,  6.1453e-02,  ...,  4.8308e-02,\n",
            "           2.7695e-02, -1.9385e-03]],\n",
            "\n",
            "        [[-1.0795e-01, -4.8843e-02,  7.6562e-02,  ...,  1.9854e-02,\n",
            "          -1.1330e-02,  3.9048e-02]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-6.3185e-02,  5.6127e-03,  6.8614e-05,  ...,  8.7976e-02,\n",
            "          -1.2266e-02, -6.8669e-02]],\n",
            "\n",
            "        [[-4.6364e-03, -5.7164e-02,  1.8857e-03,  ...,  1.0970e-02,\n",
            "          -1.8441e-02, -1.1024e-01]],\n",
            "\n",
            "        [[ 5.1901e-03, -5.9596e-03, -4.7625e-02,  ..., -8.5453e-03,\n",
            "          -4.6074e-03, -8.2608e-02]]], grad_fn=<StackBackward>)\n",
            "(tensor([[[ 0.0052, -0.0060, -0.0476, -0.0296,  0.0757, -0.0301, -0.0730,\n",
            "           0.0047,  0.0144, -0.0634,  0.0119, -0.0057, -0.0329, -0.0289,\n",
            "           0.0857, -0.0485,  0.0093, -0.0384, -0.0067, -0.0032,  0.0733,\n",
            "           0.0095, -0.0504,  0.0012, -0.0327, -0.0112,  0.0373,  0.0660,\n",
            "           0.0611,  0.0713, -0.0808, -0.0046, -0.0320, -0.0377,  0.0324,\n",
            "          -0.0347,  0.0358,  0.0815, -0.0225,  0.0312, -0.1027, -0.0168,\n",
            "           0.0046, -0.0533, -0.0016, -0.0360,  0.0355, -0.0227, -0.0606,\n",
            "           0.0391,  0.0111, -0.0697,  0.0399,  0.0596,  0.0335,  0.0607,\n",
            "           0.0895, -0.0069,  0.0734, -0.0909,  0.0407,  0.0174,  0.0215,\n",
            "           0.0297,  0.0395,  0.0228,  0.0693, -0.0100,  0.1328,  0.0185,\n",
            "           0.0035, -0.0509, -0.0371, -0.0079,  0.1104, -0.0570, -0.0719,\n",
            "           0.1061,  0.1062, -0.0172, -0.0054,  0.0228,  0.0093,  0.0147,\n",
            "          -0.0555,  0.0210,  0.0415,  0.0242,  0.0420, -0.0653, -0.0281,\n",
            "           0.0207,  0.0942, -0.0101,  0.0441,  0.1055, -0.0845, -0.0548,\n",
            "           0.0339,  0.0276,  0.0332,  0.0209, -0.0482, -0.0673,  0.0131,\n",
            "          -0.0285, -0.1274, -0.0357,  0.0191, -0.0578,  0.0525, -0.0327,\n",
            "           0.0661, -0.0233, -0.0183, -0.0118, -0.0475,  0.0819, -0.0191,\n",
            "          -0.0096,  0.0283,  0.0639,  0.0632, -0.0245, -0.0291, -0.0085,\n",
            "          -0.0046, -0.0826]]], grad_fn=<StackBackward>), tensor([[[ 0.0110, -0.0122, -0.1017, -0.0556,  0.1476, -0.0566, -0.1370,\n",
            "           0.0092,  0.0261, -0.1177,  0.0254, -0.0117, -0.0634, -0.0570,\n",
            "           0.1651, -0.1056,  0.0175, -0.0675, -0.0132, -0.0065,  0.1411,\n",
            "           0.0202, -0.0945,  0.0025, -0.0645, -0.0238,  0.0713,  0.1212,\n",
            "           0.1307,  0.1496, -0.1452, -0.0089, -0.0647, -0.0731,  0.0681,\n",
            "          -0.0702,  0.0706,  0.1662, -0.0395,  0.0724, -0.1928, -0.0327,\n",
            "           0.0083, -0.1097, -0.0031, -0.0728,  0.0718, -0.0430, -0.1267,\n",
            "           0.0751,  0.0237, -0.1664,  0.0841,  0.1104,  0.0648,  0.1067,\n",
            "           0.1784, -0.0152,  0.1652, -0.1940,  0.0815,  0.0336,  0.0433,\n",
            "           0.0573,  0.0820,  0.0487,  0.1415, -0.0190,  0.2682,  0.0419,\n",
            "           0.0070, -0.0982, -0.0690, -0.0149,  0.2458, -0.1181, -0.1242,\n",
            "           0.2284,  0.2101, -0.0317, -0.0118,  0.0452,  0.0186,  0.0334,\n",
            "          -0.1166,  0.0452,  0.0904,  0.0493,  0.0939, -0.1365, -0.0590,\n",
            "           0.0492,  0.1876, -0.0203,  0.0965,  0.2369, -0.1672, -0.1094,\n",
            "           0.0746,  0.0578,  0.0636,  0.0404, -0.0836, -0.1520,  0.0239,\n",
            "          -0.0591, -0.2589, -0.0683,  0.0423, -0.1133,  0.1130, -0.0721,\n",
            "           0.1246, -0.0543, -0.0403, -0.0237, -0.0946,  0.1544, -0.0367,\n",
            "          -0.0191,  0.0593,  0.1207,  0.1389, -0.0498, -0.0538, -0.0199,\n",
            "          -0.0103, -0.1669]]], grad_fn=<StackBackward>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TCPAGk2uSC1"
      },
      "source": [
        "# nn.Moduleを継承して新しいクラスを作る。決まり文句\n",
        "class LSTMClassifier(nn.Module):\n",
        "    # モデルで使う各ネットワークをコンストラクタで定義\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        # 親クラスのコンストラクタ。決まり文句\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # インプットの単語をベクトル化するために使う\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "        # softmaxのLog版。dim=0で列、dim=1で行方向を確率変換。\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    # 順伝播処理はforward関数に記載\n",
        "    def forward(self, sentence):\n",
        "        # 文章内の各単語をベクトル化して出力。2次元のテンソル\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
        "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値だけ使う。\n",
        "        _, lstm_out = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
        "        tag_space = self.hidden2tag(lstm_out[0].view(-1, self.hidden_dim))\n",
        "        # softmaxに食わせて、確率として表現\n",
        "        tag_scores = self.softmax(tag_space)\n",
        "        return tag_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3l_1mI5uXpI",
        "outputId": "0ab14b58-d380-45e1-fa22-bd6ff7264af6"
      },
      "source": [
        "category2index = {}\n",
        "for cat in categories:\n",
        "    if cat in category2index: continue\n",
        "    category2index[cat] = len(category2index)\n",
        "print(category2index)\n",
        "#{'movie-enter': 0, 'it-life-hack': 1, 'kaden-channel': 2, 'topic-news': 3, 'livedoor-homme': 4, 'peachy': 5, 'sports-watch': 6, 'dokujo-tsushin': 7, 'smax': 8}\n",
        "\n",
        "def category2tensor(cat):\n",
        "    return torch.tensor([category2index[cat]], dtype=torch.long)\n",
        "\n",
        "print(category2tensor(\"it-life-hack\"))\n",
        "# tensor([1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'peachy': 0, 'livedoor-homme': 1, 'it-life-hack': 2, 'movie-enter': 3, 'sports-watch': 4, 'smax': 5, 'kaden-channel': 6, 'dokujo-tsushin': 7, 'topic-news': 8}\n",
            "tensor([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFKS4VXlub-1",
        "outputId": "f8d3d8f8-9908-4097-caf4-28e1794f2092"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "# 元データを7:3に分ける（7->学習、3->テスト）\n",
        "traindata, testdata = train_test_split(datasets, train_size=0.7)\n",
        "\n",
        "# 単語のベクトル次元数\n",
        "EMBEDDING_DIM = 10\n",
        "# 隠れ層の次元数\n",
        "HIDDEN_DIM = 128\n",
        "# データ全体の単語数\n",
        "VOCAB_SIZE = len(word2index)\n",
        "# 分類先のカテゴリの数\n",
        "TAG_SIZE = len(categories)\n",
        "# モデル宣言\n",
        "model = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE, TAG_SIZE)\n",
        "# 損失関数はNLLLoss()を使う。LogSoftmaxを使う時はこれを使うらしい。\n",
        "loss_function = nn.NLLLoss()\n",
        "# 最適化の手法はSGDで。lossの減りに時間かかるけど、一旦はこれを使う。\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# 各エポックの合計loss値を格納する\n",
        "losses = []\n",
        "# 100ループ回してみる。（バッチ化とかGPU使ってないので結構時間かかる...）\n",
        "for epoch in range(100):\n",
        "    all_loss = 0\n",
        "    for title, cat in zip(traindata[\"title\"], traindata[\"category\"]):\n",
        "        # モデルが持ってる勾配の情報をリセット\n",
        "        model.zero_grad()\n",
        "        # 文章を単語IDの系列に変換（modelに食わせられる形に変換）\n",
        "        inputs = sentence2index(title)\n",
        "        # 順伝播の結果を受け取る\n",
        "        out = model(inputs)\n",
        "        # 正解カテゴリをテンソル化\n",
        "        answer = category2tensor(cat)\n",
        "        # 正解とのlossを計算\n",
        "        loss = loss_function(out, answer)\n",
        "        # 勾配をセット\n",
        "        loss.backward()\n",
        "        # 逆伝播でパラメータ更新\n",
        "        optimizer.step()\n",
        "        # lossを集計\n",
        "        all_loss += loss.item()\n",
        "    losses.append(all_loss)\n",
        "    print(\"epoch\", epoch, \"\\t\" , \"loss\", all_loss)\n",
        "print(\"done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 \t loss 11019.400385141373\n",
            "epoch 1 \t loss 10216.27023331821\n",
            "epoch 2 \t loss 9413.558435201645\n",
            "epoch 3 \t loss 8762.354743001983\n",
            "epoch 4 \t loss 8200.416140274145\n",
            "epoch 5 \t loss 7678.259021232603\n",
            "epoch 6 \t loss 7182.8662072317675\n",
            "epoch 7 \t loss 6715.630126240896\n",
            "epoch 8 \t loss 6281.116249682789\n",
            "epoch 9 \t loss 5881.546746600943\n",
            "epoch 10 \t loss 5613.708644058701\n",
            "epoch 11 \t loss 5117.234844568011\n",
            "epoch 12 \t loss 4715.216110028923\n",
            "epoch 13 \t loss 4298.017658276498\n",
            "epoch 14 \t loss 3878.6192948155185\n",
            "epoch 15 \t loss 3443.949579124819\n",
            "epoch 16 \t loss 3012.5058112450733\n",
            "epoch 17 \t loss 2564.2704926020238\n",
            "epoch 18 \t loss 2155.053878522586\n",
            "epoch 19 \t loss 1737.3363366552428\n",
            "epoch 20 \t loss 1365.4779011653682\n",
            "epoch 21 \t loss 1131.0684179004716\n",
            "epoch 22 \t loss 805.1157771816696\n",
            "epoch 23 \t loss 535.7107901094704\n",
            "epoch 24 \t loss 558.4800955573522\n",
            "epoch 25 \t loss 386.3579472255079\n",
            "epoch 26 \t loss 271.49811416906334\n",
            "epoch 27 \t loss 157.83489891885853\n",
            "epoch 28 \t loss 121.93418756843838\n",
            "epoch 29 \t loss 92.04638359889739\n",
            "epoch 30 \t loss 76.63234214504271\n",
            "epoch 31 \t loss 65.737052002115\n",
            "epoch 32 \t loss 58.3964748724236\n",
            "epoch 33 \t loss 52.88293203729968\n",
            "epoch 34 \t loss 48.54733429015226\n",
            "epoch 35 \t loss 45.053283956188096\n",
            "epoch 36 \t loss 42.17703019598448\n",
            "epoch 37 \t loss 39.76361544902431\n",
            "epoch 38 \t loss 37.706980115372225\n",
            "epoch 39 \t loss 35.93278561634757\n",
            "epoch 40 \t loss 34.386560510003044\n",
            "epoch 41 \t loss 33.02728989084547\n",
            "epoch 42 \t loss 31.82317434684488\n",
            "epoch 43 \t loss 30.748477605310008\n",
            "epoch 44 \t loss 29.78304609159209\n",
            "epoch 45 \t loss 28.910886501553016\n",
            "epoch 46 \t loss 28.118929996368067\n",
            "epoch 47 \t loss 27.396415696484922\n",
            "epoch 48 \t loss 26.73445346086755\n",
            "epoch 49 \t loss 26.125617320695888\n",
            "epoch 50 \t loss 25.563631874030676\n",
            "epoch 51 \t loss 25.04319741096357\n",
            "epoch 52 \t loss 24.559794011996352\n",
            "epoch 53 \t loss 24.10956770302103\n",
            "epoch 54 \t loss 23.68915007958303\n",
            "epoch 55 \t loss 23.2957096243422\n",
            "epoch 56 \t loss 22.926720925680968\n",
            "epoch 57 \t loss 22.5799602707797\n",
            "epoch 58 \t loss 22.253522891605137\n",
            "epoch 59 \t loss 21.94569990956196\n",
            "epoch 60 \t loss 21.654928625915495\n",
            "epoch 61 \t loss 21.37984088593734\n",
            "epoch 62 \t loss 21.11923555741248\n",
            "epoch 63 \t loss 20.871971089142157\n",
            "epoch 64 \t loss 20.637068025102828\n",
            "epoch 65 \t loss 20.413621950169343\n",
            "epoch 66 \t loss 20.200763418136916\n",
            "epoch 67 \t loss 19.99778754980347\n",
            "epoch 68 \t loss 19.80400625090246\n",
            "epoch 69 \t loss 19.618776948306476\n",
            "epoch 70 \t loss 19.441556232664418\n",
            "epoch 71 \t loss 19.271746204772214\n",
            "epoch 72 \t loss 19.108903301089924\n",
            "epoch 73 \t loss 18.952631871756573\n",
            "epoch 74 \t loss 18.802588156768486\n",
            "epoch 75 \t loss 18.658401072622247\n",
            "epoch 76 \t loss 18.51973217776704\n",
            "epoch 77 \t loss 18.38626202889261\n",
            "epoch 78 \t loss 18.257674023176072\n",
            "epoch 79 \t loss 18.13370531219588\n",
            "epoch 80 \t loss 18.014121036023333\n",
            "epoch 81 \t loss 17.898673177940175\n",
            "epoch 82 \t loss 17.787173279387737\n",
            "epoch 83 \t loss 17.67939163774645\n",
            "epoch 84 \t loss 17.5751360309091\n",
            "epoch 85 \t loss 17.47426459150865\n",
            "epoch 86 \t loss 17.376598209049078\n",
            "epoch 87 \t loss 17.28199350602072\n",
            "epoch 88 \t loss 17.190299928476037\n",
            "epoch 89 \t loss 17.10137013023413\n",
            "epoch 90 \t loss 17.01510960453068\n",
            "epoch 91 \t loss 16.931385482479833\n",
            "epoch 92 \t loss 16.85006177595845\n",
            "epoch 93 \t loss 16.771073236519776\n",
            "epoch 94 \t loss 16.69429994540235\n",
            "epoch 95 \t loss 16.619643730383686\n",
            "epoch 96 \t loss 16.547028368654075\n",
            "epoch 97 \t loss 16.476379971220872\n",
            "epoch 98 \t loss 16.40760709213395\n",
            "epoch 99 \t loss 16.340611492664543\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "HasbyzhxuhCe",
        "outputId": "0ccc32c4-b912-4950-f7f9-8efb1c0a888d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa085cae450>]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyjshBl6usEj"
      },
      "source": [
        "過学習を疑う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UyGq31vuqFX",
        "outputId": "fb2b7f2d-d9db-4c0a-f88c-56fab4968f25"
      },
      "source": [
        "traindata_num = len(traindata)\n",
        "a = 0\n",
        "with torch.no_grad():\n",
        "    for title, category in zip(traindata[\"title\"], traindata[\"category\"]):\n",
        "        inputs = sentence2index(title)\n",
        "        out = model(inputs)\n",
        "        _, predict = torch.max(out, 1)\n",
        "        answer = category2tensor(category)\n",
        "        if predict == answer:\n",
        "            a += 1\n",
        "print(\"predict : \", a / traindata_num)\n",
        "# predict :  0.9984505132674801"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict :  0.9990315707921751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqvkkkKPu0LL",
        "outputId": "44ff5ccb-9d64-4199-9ca9-bc9dd23f3790"
      },
      "source": [
        "import collections\n",
        "# IDをカテゴリに戻す用\n",
        "index2category = {}\n",
        "for cat, idx in category2index.items():\n",
        "    index2category[idx] = cat\n",
        "\n",
        "# answer -> 正解ラベル、predict->LSTMの予測結果、exact->正解してたらO,間違っていたらX\n",
        "predict_df = pd.DataFrame(columns=[\"answer\", \"predict\", \"exact\"])\n",
        "\n",
        "# 予測して結果を上のDFに格納\n",
        "with torch.no_grad():\n",
        "    for title, category in zip(testdata[\"title\"], testdata[\"category\"]):\n",
        "        out = model(sentence2index(title))\n",
        "        _, predict = torch.max(out, 1)\n",
        "        answer = category2tensor(category)\n",
        "        exact = \"O\" if predict.item() == answer.item() else \"X\"\n",
        "        s = pd.Series([answer.item(), predict.item(), exact], index=predict_df.columns)\n",
        "        predict_df = predict_df.append(s, ignore_index=True)\n",
        "\n",
        "# Fスコア格納用のDF\n",
        "fscore_df = pd.DataFrame(columns=[\"category\", \"all\",\"precison\", \"recall\", \"fscore\"])\n",
        "\n",
        "# 分類器が答えた各カテゴリの件数\n",
        "prediction_count = collections.Counter(predict_df[\"predict\"])\n",
        "# 各カテゴリの総件数\n",
        "answer_count = collections.Counter(predict_df[\"answer\"])\n",
        "\n",
        "# Fスコア求める\n",
        "for i in range(9):\n",
        "    all_count = answer_count[i]\n",
        "    precision = len(predict_df.query('predict == ' + str(i) + ' and exact == \"O\"')) / prediction_count[i]\n",
        "    recall = len(predict_df.query('answer == ' + str(i) + ' and exact == \"O\"')) / all_count\n",
        "    fscore = 2*precision*recall / (precision + recall)\n",
        "    s = pd.Series([index2category[i], all_count, round(precision, 2), round(recall, 2), round(fscore, 2)], index=fscore_df.columns)\n",
        "    fscore_df = fscore_df.append(s, ignore_index=True)\n",
        "print(fscore_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         category  all  precison  recall  fscore\n",
            "0          peachy  232      0.46    0.45    0.46\n",
            "1  livedoor-homme  162      0.57    0.54    0.55\n",
            "2    it-life-hack  266      0.65    0.67    0.66\n",
            "3     movie-enter  256      0.49    0.53    0.51\n",
            "4    sports-watch  276      0.51    0.53    0.52\n",
            "5            smax  269      0.88    0.84    0.86\n",
            "6   kaden-channel  264      0.86    0.83    0.85\n",
            "7  dokujo-tsushin  245      0.61    0.67    0.64\n",
            "8      topic-news  243      0.58    0.52    0.55\n"
          ]
        }
      ]
    }
  ]
}
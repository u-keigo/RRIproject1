{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_hurst3-2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMo6TUdiDXQE3IJ9RbH/ezn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/u-keigo/RRIproject1/blob/main/LSTM_hurst3_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "off0ybXVLahB"
      },
      "source": [
        "# ハースト指数を予測する\n",
        "## （バッチ化に挑戦）\n",
        "### 失敗した"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvrAI48HLZs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f7658a-5995-4ed5-d18b-43b81da3931a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1mjucopLnUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac3f72d-987b-4ddd-bdb6-f1e37e9c9467"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import linecache\n",
        "\n",
        "\n",
        "def read_Gauss(name):\n",
        "  nums = []  # 整数を入れるリスト\n",
        "  with open(name, 'r', encoding='utf-8') as fin:  # ファイルを開く\n",
        "    for line in fin.readlines():  # 行を読み込んでfor文で回す\n",
        "        try:\n",
        "            line = line.replace('\\n','')\n",
        "            num = float(line)  # 行を整数（int）に変換する\n",
        "        except ValueError as e:\n",
        "            print(e, file=sys.stderr)  # エラーが出たら画面に出力\n",
        "            continue\n",
        "\n",
        "        nums.append(num)  # 変換した整数をリストに保存する\n",
        "  return (nums)\n",
        "\n",
        "\n",
        "# カテゴリを配列で取得\n",
        "drive_dir = \"/content/drive/My Drive/python/\"\n",
        "\n",
        "categories = [name for name in os.listdir(drive_dir + 'data_gauss') if os.path.isdir(drive_dir + \"data_gauss/\" +name)]\n",
        "print(categories)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['H=0.1', 'H=0.9', 'H=0.7', 'H=0.8', 'H=0.6', 'H=0.5', 'H=0.4', 'H=0.3', 'H=0.2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "AD5YAHdlctKv",
        "outputId": "815fa6f4-9559-4571-f879-3faeedf9fbbd"
      },
      "source": [
        "import numpy as np\n",
        "DAT = pd.DataFrame(np.zeros(shape=(1024, (32*9))))\n",
        "i=0\n",
        "for cat in categories:\n",
        "    path = drive_dir + \"data_gauss/\" + cat + \"/*.rri\"\n",
        "    files = glob(path)\n",
        "    for text_name in files:\n",
        "      data = pd.Series(read_Gauss(text_name))\n",
        "      DAT.iloc[:, i] = data\n",
        "      DAT.rename(columns={i: cat}, inplace=True)\n",
        "      i = i+1\n",
        "\n",
        "\n",
        "# データフレームシャッフル\n",
        "DAT = DAT.sample(frac=1,axis=1).reset_index(drop=True)\n",
        "DAT.T.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-da1897dac0d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtext_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_Gauss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mDAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mDAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1e959853c040>\u001b[0m in \u001b[0;36mread_Gauss\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 整数を入れるリスト\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# ファイルを開く\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 行を読み込んでfor文で回す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nQbIVvqdDWk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "category2index = {}\n",
        "for cat in categories:\n",
        "    if cat in category2index: continue\n",
        "    category2index[cat] = len(category2index)\n",
        "print(category2index)\n",
        "\n",
        "\n",
        "def category2tensor(cat):\n",
        "    return torch.tensor([category2index[cat]], dtype=torch.long)\n",
        "\n",
        "# データフレームの形状変更・indexの要素化\n",
        "df = DAT.T\n",
        "df['index'] = df.index\n",
        "\n",
        "df_label = df.loc[:, 'index']\n",
        "df_data = df.drop('index', axis=1)\n",
        "\n",
        "dlen = len(DAT.columns)  # 288\n",
        "train_x, test_x, train_y, test_y = train_test_split(df_data, df_label, test_size=0.3, random_state=0)\n",
        "\n",
        "\n",
        "train_x2 = torch.FloatTensor(train_x.values)\n",
        "test_x2 = torch.FloatTensor(test_x.values)\n",
        "train_y2, _ = pd.factorize(train_y)   # カテゴリー変数を数値に変換\n",
        "test_y2, _ = pd.factorize(test_y)\n",
        "\n",
        "train_y2 = torch.FloatTensor(train_y2)\n",
        "test_y2 = torch.FloatTensor(test_y2)\n",
        "\n",
        "# 次元を増やさないといけない？\n",
        "train_x2 = train_x2.unsqueeze(2)\n",
        "train_y2 = train_y2.unsqueeze(1)\n",
        "test_x2 = test_x2.unsqueeze(2)\n",
        "test_y2 = test_y2.unsqueeze(1)\n",
        "\n",
        "\n",
        "# 特徴量とラベルを結合したデータセットを作成\n",
        "train_dataset = TensorDataset(train_x2, train_y2)\n",
        "test_dataset = TensorDataset(test_x2, test_y2)\n",
        "\n",
        "\n",
        "# DataLoaderを使って、データセットを128個のミニパッチに分ける\n",
        "# ミニパッチサイズを指定したデータローダを作成\n",
        "train_batch = DataLoader(\n",
        "    dataset = train_dataset,   # データセットの指定\n",
        "    batch_size = 32,   # バッチサイズの指定\n",
        "    shuffle = True,    # シャッフルするかどうかの指定\n",
        "    num_workers = 2)   # コアの数\n",
        "\n",
        "test_batch = DataLoader(\n",
        "    dataset = test_dataset,   # データセットの指定\n",
        "    batch_size = 32,   # バッチサイズの指定\n",
        "    shuffle = False,    # シャッフルするかどうかの指定\n",
        "    num_workers = 2)   # コアの数\n",
        "\n",
        "\n",
        "# ミニバッチデータセットの確認\n",
        "for data, label in train_batch:\n",
        "  print(\"batch data size: {}\". format(data.size()))  # バッチの入力データサイズ\n",
        "  print(\"batch label size: {}\". format(label.size()))   # バッチのラベルサイズ\n",
        "  break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPSXmCWA6pc1"
      },
      "source": [
        "# nn.Moduleを継承して新しいクラスを作る。決まり文句\n",
        "class LSTMClassifier(nn.Module):\n",
        "    # モデルで使う各ネットワークをコンストラクタで定義\n",
        "    def __init__(self, embedding_dim, hidden_dim, tagset_size):\n",
        "        # 親クラスのコンストラクタ。決まり文句\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        # 隠れ層の次元数。これは好きな値に設定しても行列計算の過程で出力には出てこないので。\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # LSTMの隠れ層。これ１つでOK。超便利。\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)   # inputsの最初の次元がバッチサイズとして認識される\n",
        "        # LSTMの出力を受け取って全結合してsoftmaxに食わせるための１層のネットワーク\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "        self.softmax = nn.LogSoftmax()\n",
        "\n",
        "    # 順伝播処理はforward関数に記載\n",
        "    def forward(self, embeds):\n",
        "        # 2次元テンソルをLSTMに食わせられる様にviewで３次元テンソルにした上でLSTMへ流す。\n",
        "        # 上記で説明した様にmany to oneのタスクを解きたいので、第二戻り値だけ使う。\n",
        "        # embeds.size() = (batch_size × len(sentence) × embedding_dim)\n",
        "        _, lstm_out = self.lstm(embeds)\n",
        "        # lstm_out[0]は３次元テンソルになってしまっているので2次元に調整して全結合。\n",
        "        tag_space = self.hidden2tag(lstm_out[0])\n",
        "        # tag_space.size() = (1 × batch_size × tagset_size)\n",
        "\n",
        "        # softmaxに食わせて、確率として表現\n",
        "        # (batch_size × tagset_size)にするためにsqueeze()する\n",
        "        tag_scores = self.softmax(tag_space.squeeze())\n",
        "        # tag_scores.size() = (batch_size × tagset_size)\n",
        "\n",
        "        return tag_scores\n",
        "\n",
        "category2index = {}\n",
        "for cat in categories:\n",
        "    if cat in category2index: continue\n",
        "    category2index[cat] = len(category2index)\n",
        "print(category2index)\n",
        "\n",
        "def category2tensor(cat):\n",
        "    return torch.tensor([category2index[cat]], dtype=torch.long)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmcMN4RA9XjU"
      },
      "source": [
        "# 入力次元数\n",
        "EMBEDDING_DIM = 1\n",
        "# 隠れ層の次元数\n",
        "HIDDEN_DIM = 128\n",
        "# 分類先のカテゴリの数\n",
        "TAG_SIZE = len(categories)\n",
        "\n",
        "# ネットワークのロード\n",
        "# CPUとGPUのどちらを使うかを指定\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net = LSTMClassifier(EMBEDDING_DIM, HIDDEN_DIM, TAG_SIZE).to(device)\n",
        "# デバイスの確認\n",
        "print(\"Device: {}\".format(device))\n",
        "\n",
        "\n",
        "loss_function = nn.MSELoss()  # 損失関数（平均二乗誤差：MSE）\n",
        "# 最適化関数の定義\n",
        "# optimizer = optim.Adam(net.parameters())\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# 損失を保存するリストを作成\n",
        "train_loss_list = []  # 学習損失\n",
        "test_loss_list = []  # 評価損失\n",
        "\n",
        "epoch = 100\n",
        "\n",
        "for i in range(epoch):\n",
        "  all_loss = 0\n",
        "  # エポックの進行状況を表示\n",
        "  print('-------------------------------------')\n",
        "  print(\"Epoch: {}/{}\".format(i+1,epoch))\n",
        "\n",
        "  # 損失の初期化\n",
        "  train_loss = 0  # 学習損失\n",
        "  test_loss = 0  # 評価損失\n",
        "\n",
        "  # ---学習パート--- #\n",
        "  # ニューラルネットワークを学習モードに設定\n",
        "  net.train()\n",
        "  for j, (xx, yy) in enumerate(train_batch):\n",
        "        # モデルが持ってる勾配の情報をリセット\n",
        "        net.zero_grad()\n",
        "        inputs = xx.cuda()\n",
        "        # GPUにTensorを転送\n",
        "        inputs = inputs.to(device)\n",
        "        # 順伝播の結果を受け取る\n",
        "        out = net(inputs)\n",
        "        answer = yy.cuda()\n",
        "        # GPUにTensorを転送\n",
        "        answer = answer.to(device)\n",
        "        # 正解とのlossを計算\n",
        "        loss = loss_function(out, answer)\n",
        "        # 勾配をセット\n",
        "        loss.backward()\n",
        "        # 逆伝播でパラメータ更新\n",
        "        optimizer.step()\n",
        "        # lossを集計\n",
        "        train_loss += loss.item()\n",
        "  \n",
        "  # ミニバッチの平均の損失を計算\n",
        "  batch_train_loss = train_loss / len(train_batch)\n",
        "  # ---学習パートはここまで--- #\n",
        "\n",
        "  # ---評価パート--- #\n",
        "  # ニューラルネットワークを評価モードに設定\n",
        "  net.eval()\n",
        "  # 評価時の計算で自動微分機能をオフにする\n",
        "  with torch.no_grad():\n",
        "    for j, (xx, yy) in enumerate(test_batch):\n",
        "        inputs = xx.cuda()\n",
        "        # GPUにTensorを転送\n",
        "        inputs = inputs.to(device)\n",
        "        # 順伝播の結果を受け取る\n",
        "        out = net(inputs)\n",
        "        answer = yy.cuda()\n",
        "        # GPUにTensorを転送\n",
        "        answer = answer.to(device)\n",
        "        # 正解とのlossを計算\n",
        "        loss = loss_function(out, answer)\n",
        "        # lossを集計\n",
        "        test_loss += loss.item()\n",
        "\n",
        "    \n",
        "  # ミニバッチの平均の損失を計算\n",
        "  batch_test_loss = test_loss / len(test_batch)\n",
        "  # ---評価パートはここまで--- #\n",
        "\n",
        "  # エポックごとに損失を表示\n",
        "  print(\"Train_Loss : {:.2E} Test_Loss: {:.2E}\".format(\n",
        "      batch_train_loss, batch_test_loss))\n",
        "  # 損失をリスト化して保存\n",
        "  train_loss_list.append(batch_train_loss)\n",
        "  test_loss_list.append(batch_test_loss)\n",
        "print(\"done.\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W37NkMH49FFa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# 損失\n",
        "# 損失\n",
        "fig2 = plt.figure()\n",
        "plt.title('Train and Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(range(1, epoch+1), train_loss_list, color='blue',\n",
        "         linestyle='-', label='Train_Loss')\n",
        "plt.plot(range(1, epoch+1), test_loss_list, color='red',\n",
        "         linestyle='--', label='Test_Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}